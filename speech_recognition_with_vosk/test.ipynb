{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio(paApi=pyaudio.paALSA)\n",
    "\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i))\n",
    "\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "from recase import Config, WordpieceTokenizer, Model, init, gen_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6f9ef8f48c47168d9b58a044266f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Record', icon='microphone', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5e879b23cc409d8af970d08180774b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Stop', icon='stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f43590243904386b497e95370e1551a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(_dom_classes=('output-overflow',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:1369:(snd_func_refer) Unable to find definition 'cards.1.pcm.modem.0:CARD=1'\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline:CARD=1,DEV=0\n",
      "ALSA lib confmisc.c:1369:(snd_func_refer) Unable to find definition 'cards.1.pcm.modem.0:CARD=1'\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline:CARD=1,DEV=0\n",
      "ALSA lib confmisc.c:1369:(snd_func_refer) Unable to find definition 'cards.1.pcm.modem.0:CARD=1'\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM phoneline\n",
      "ALSA lib confmisc.c:1369:(snd_func_refer) Unable to find definition 'cards.1.pcm.modem.0:CARD=1'\n",
      "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM phoneline\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import IPython.display as display\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "messages = Queue()\n",
    "recordings = Queue()\n",
    "\n",
    "record_button = widgets.Button(\n",
    "    description=\"Record\",\n",
    "    disabled=False,\n",
    "    button_style=\"success\",\n",
    "    icon=\"microphone\"\n",
    ")\n",
    "\n",
    "stop_button = widgets.Button(\n",
    "    description=\"Stop\",\n",
    "    disabled=False,\n",
    "    button_style=\"warning\",\n",
    "    icon=\"stop\"\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Add custom CSS to allow overflow\n",
    "output.add_class(\"output-overflow\")\n",
    "\n",
    "def start_recording(data):\n",
    "    messages.put(True)\n",
    "    with output:\n",
    "        # display.display(\"Starting...\")\n",
    "        print(\"Starting...\")\n",
    "        record = Thread(target=record_microphone)\n",
    "        record.start()\n",
    "\n",
    "        transcribe = Thread(target=speech_recognition, args=(output,))\n",
    "        transcribe.start()\n",
    "\n",
    "def stop_recording(data):\n",
    "    with output:\n",
    "        messages.get()\n",
    "        # display.display(\"Stopped...\")\n",
    "        print(\"Stopped...\")\n",
    "\n",
    "record_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "\n",
    "display.display(record_button, stop_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 1\n",
    "FRAME_RATE = 16000\n",
    "RECORD_SECONDS = 3\n",
    "AUDIO_FORMAT = pyaudio.paInt16\n",
    "SAMPLE_SIZE = 0\n",
    "\n",
    "def record_microphone(chunk=1024):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=AUDIO_FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=FRAME_RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk\n",
    "                    )\n",
    "    frames = []\n",
    "    while not messages.empty():\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "        if len(frames) >= (FRAME_RATE * RECORD_SECONDS) / chunk:\n",
    "            recordings.put(frames.copy())\n",
    "            frames=[]\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:11:12:13:14:15\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from ./vosk-model-en-us-0.22/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from ./vosk-model-en-us-0.22/graph/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:297) Loading words from ./vosk-model-en-us-0.22/graph/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo ./vosk-model-en-us-0.22/graph/phones/word_boundary.int\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:315) Loading subtract G.fst model from ./vosk-model-en-us-0.22/rescore/G.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:317) Loading CARPA model from ./vosk-model-en-us-0.22/rescore/G.carpa\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:323) Loading RNNLM model from ./vosk-model-en-us-0.22/rnnlm/final.raw\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import time\n",
    "\n",
    "model = Model(model_name=\"vosk-model-en-us-0.22\", model_path=\"./vosk-model-en-us-0.22\")\n",
    "rec = KaldiRecognizer(model, FRAME_RATE)\n",
    "rec.SetWords(True)\n",
    "\n",
    "def speech_recognition(output):\n",
    "    temp_text = ''\n",
    "    while not messages.empty():\n",
    "        frames = recordings.get()\n",
    "        waveform_data = b''.join(frames)\n",
    "        rec.AcceptWaveform(waveform_data)\n",
    "        result = rec.Result()\n",
    "\n",
    "        text1 = json.loads(result)[\"text\"]\n",
    "        # load_text = temp_text + text1\n",
    "\n",
    "\n",
    "        # config = Config(action='predict', lang='en', flavor=None, device='cpu')\n",
    "        # init(config)\n",
    "        # checkpoint_path = 'vosk-recasepunc-en-0.22/checkpoint'\n",
    "\n",
    "        # cased = gen_pred(config, checkpoint_path, load_text)\n",
    "\n",
    "        # puncs = ['.', '?', '!']\n",
    "\n",
    "        # last_punctuation_index = max([cased.rfind(p) for p in puncs])\n",
    "\n",
    "        # if cased[-1] in puncs:\n",
    "        #     pass\n",
    "        \n",
    "        # elif last_punctuation_index == -1:\n",
    "        #     temp_text = cased\n",
    "        #     cased = ''\n",
    "        # else:\n",
    "        #     temp_text = cased[last_punctuation_index + 1:].strip()\n",
    "        #     cased = cased[:last_punctuation_index + 1].strip()\n",
    "\n",
    "        # cased = subprocess.check_output(\"python vosk-recasepunc-en-0.22/recasepunc.py predict vosk-recasepunc-en-0.22/checkpoint\", shell=True, text=True, input=text1)\n",
    "        output.append_stdout(text1)\n",
    "        # with output:\n",
    "        #     output.append_stdout(cased)\n",
    "        #     print(cased)\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1='hello this is saad and today we are going to be talking about the fundamentals of programming subscribing really helps the channel so please make sure to leave a like how about we go over the details now'\n",
    "config = Config(action='predict', lang='en', flavor=None, device='cpu')\n",
    "init(config)\n",
    "checkpoint_path = 'vosk-recasepunc-en-0.22/checkpoint'\n",
    "\n",
    "gen_pred(config, checkpoint_path, t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
